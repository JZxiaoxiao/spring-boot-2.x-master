server.port=8071
# encode
spring.banner.charset=UTF-8
server.tomcat.uri-encoding=UTF-8
spring.http.encoding.charset=UTF-8
spring.http.encoding.enabled=true
spring.http.encoding.force=true
spring.messages.encoding=UTF-8
# 取消web
spring.main.web-application-type=none
# log 集群模式取消
logging.config=classpath:logback.xml

#Spring Boot 2.0 默认数据源 HikariDataSource
#spring.datasource.type=com.zaxxer.hikari.HikariDataSource
spring.datasource.hikari.pool-name=HikariDataSourcePool
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/db1?useUnicode=true&characterEncoding=utf8&allowMultiQueries=true&useSSL=false
spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
#自动提交
spring.datasource.hikari.auto-commit=true
## 最小空闲连接数量
spring.datasource.hikari.minimum-idle=5
## 空闲连接存活最大时间，默认600000（10分钟）
spring.datasource.hikari.idle-timeout=1800000
## 连接池最大连接数，默认是10
spring.datasource.hikari.maximum-pool-size=100
## 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟
spring.datasource.hikari.max-lifetime=1800000
## 数据库连接超时时间,默认30秒，即30000
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.connection-test-query=SELECT 1

# mybatis对应的映射文件路径
mybatis.mapper-locations=classpath:mybatis/mapper/*.xml
# mybatis对应的实体类
#mybatis.type-aliases-package=com.jun.springbootstorm.dao.mapper.bo

## Reids配置(默认集群)
# 单机版配置
spring.cache.type=redis
spring.redis.host=10.16.197.5
spring.redis.port=8001
# Redis服务器连接密码（默认为空）
spring.redis.password=
# 连接超时时间（毫秒）
spring.redis.timeout=10000
# 集群版本配置 多个之间用，逗号隔开（为空则用单节点）
spring.redis.cluster.nodes=
# 跨集群执行命令时要遵循的最大重定向数量
spring.redis.cluster.max-redirects=3
# 最大空闲连接数
spring.redis.jedis.pool.max-idle=8
# 最小空闲连接数
spring.redis.jedis.pool.min-idle=0
# 最大活跃连接数，负数为不限制
spring.redis.jedis.pool.max-active=8
# 等待可用连接的最大时间，负数为不限制
spring.redis.jedis.pool.max-wait=-1

## hbase配置
hbase.zookeeper.quorum=10.16.197.23,10.16.197.24,10.166.197.25
hbase.zookeeper.property.clientPort=2181

## kafka配置
kafka.servers.url=10.16.197.23\:9092
kafka.topic.name=test-storm
kafka.autoCommit=false
kafka.maxPollRecords=100
kafka.group.id=test-consumer-group
kafka.commitRule=earliest